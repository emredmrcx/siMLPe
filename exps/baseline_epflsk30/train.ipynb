{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from config import config\n",
    "from model import siMLPe as Model\n",
    "from datasets.epfl_sk30 import EPFLSK30Dataset\n",
    "from utils.logger import get_logger, print_and_log_info\n",
    "from utils.pyt_utils import link_file, ensure_dir\n",
    "from datasets.epfl_sk30_eval import EPFLSK30Eval\n",
    "\n",
    "from test import test\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35c2c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memredmrcx\u001b[0m (\u001b[33memredmrcx-itu-edu-tr\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ai/emre/siMLPe/exps/baseline_epflsk30/wandb/run-20251007_123612-d4snm1so</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30/runs/d4snm1so' target=\"_blank\">epfl_sk30_baseline_downsample2</a></strong> to <a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30' target=\"_blank\">https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30/runs/d4snm1so' target=\"_blank\">https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30/runs/d4snm1so</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"epfl_sk30_baseline_downsample2\"\n",
    "\n",
    "#E https://docs.pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html\n",
    "#E Throws runtime error if there only exists nondetermistic operations (AvgPool3D MaxPool3D... )\n",
    "#E Runs deterministic ones if there exists (Conv1D Conv2D Conv3D... check out the website for more)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "acc_log = open(exp_name, 'a')\n",
    "torch.manual_seed(config.seed)\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"siMLPe-EPFL-SK30\",\n",
    "    name=exp_name,\n",
    "    config={\n",
    "        \"exp_name\": exp_name,\n",
    "        \"seed\": config.seed,\n",
    "        \"with_normalization\": config.motion_mlp.with_normalization,\n",
    "        \"spatial_fc\": config.motion_mlp.spatial_fc_only,\n",
    "        \"num_layers\": config.motion_mlp.num_layers,\n",
    "        # Model config\n",
    "        \"motion_input_length\": config.motion.epfl_input_length,\n",
    "        \"motion_target_length_train\": config.motion.epfl_target_length_train,\n",
    "        \"motion_target_length_eval\": config.motion.epfl_target_length_eval,\n",
    "        \"motion_dim\": config.motion.dim,\n",
    "        \"data_aug\": config.data_aug,\n",
    "        \"deriv_input\": config.deriv_input,\n",
    "        \"deriv_output\": config.deriv_output,\n",
    "        \"use_relative_loss\": config.use_relative_loss,\n",
    "        # Training config\n",
    "        \"batch_size\": config.batch_size,\n",
    "        \"num_workers\": config.num_workers,\n",
    "        \"cos_lr_max\": config.cos_lr_max,\n",
    "        \"cos_lr_min\": config.cos_lr_min,\n",
    "        \"cos_lr_total_iters\": config.cos_lr_total_iters,\n",
    "        \"weight_decay\": config.weight_decay,\n",
    "        \"print_every\": config.print_every,\n",
    "        \"save_every\": config.save_every,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "acc_log.write(''.join('Seed : ' + str(config.seed) + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16c67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E Compute Discrete Cosine Transform (DCT) matrix and its inverse (IDCT) for a given size N. \n",
    "#E DCT matrix is used to transform data into the frequency domain, and its inverse allows transformation back to the original domain. \n",
    "def get_dct_matrix(N):\n",
    "    dct_m = np.eye(N)\n",
    "    for k in np.arange(N):\n",
    "        for i in np.arange(N):\n",
    "            w = np.sqrt(2 / N)\n",
    "            if k == 0:\n",
    "                w = np.sqrt(1 / N)\n",
    "            dct_m[k, i] = w * np.cos(np.pi * (i + 1 / 2) * k / N)\n",
    "    idct_m = np.linalg.inv(dct_m)\n",
    "    return dct_m, idct_m\n",
    "\n",
    "\n",
    "#E Compute DCT and IDCT matrices for the input length of the EPFL SK30 dataset.\n",
    "dct_m,idct_m = get_dct_matrix(config.motion.epfl_input_length_dct)\n",
    "dct_m = torch.tensor(dct_m).float().cuda().unsqueeze(0)\n",
    "idct_m = torch.tensor(idct_m).float().cuda().unsqueeze(0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62e42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr_multistep(nb_iter, total_iter, max_lr, min_lr, optimizer) :\n",
    "    if nb_iter > 30000:\n",
    "        current_lr = 1e-5\n",
    "    else:\n",
    "        current_lr = 3e-4\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = current_lr\n",
    "\n",
    "    return optimizer, current_lr\n",
    "\n",
    "#E Compute velocity for the loss function.\n",
    "def gen_velocity(m):\n",
    "    dm = m[:, 1:] - m[:, :-1]\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6237adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(epfl_motion_input, epfl_motion_target, model, optimizer, nb_iter, total_iter, max_lr, min_lr) :\n",
    "    \n",
    "    # Input shape: (b, n, 17, 3) - reshape to (b, n, 51) for model\n",
    "    b, n, num_joints, _ = epfl_motion_input.shape\n",
    "    epfl_motion_input_flat = epfl_motion_input.reshape(b, n, -1)  # (b, n, 51)\n",
    "    \n",
    "    #E config.deriv_input = True: Use DCT matrix\n",
    "    #E config.deriv_input = False: Use original input\n",
    "    if config.deriv_input:\n",
    "        epfl_motion_input_ = epfl_motion_input_flat.clone()\n",
    "        epfl_motion_input_ = torch.matmul(dct_m[:, :, :config.motion.epfl_input_length], epfl_motion_input_.cuda())\n",
    "    else:\n",
    "        epfl_motion_input_ = epfl_motion_input_flat.clone()\n",
    "\n",
    "    #E Predict the motion and use IDCT to get the original motion.\n",
    "    motion_pred = model(epfl_motion_input_.cuda())\n",
    "    motion_pred = torch.matmul(idct_m[:, :config.motion.epfl_input_length, :], motion_pred)\n",
    "\n",
    "    #E config.deriv_output = True: meaning the model predicts motion deltas (differences) rather than absolute positions. \n",
    "    #E offset = the last input frame (epfl_motion_input[:, -1:])\n",
    "    #E and it's added to the predicted deltas to reconstruct the absolute motion sequence\n",
    "    #E config.deriv_output = False: the model predicts absolute positions directly, so no offset is needed.\n",
    "    if config.deriv_output:\n",
    "        offset = epfl_motion_input_flat[:, -1:].cuda()\n",
    "        motion_pred = motion_pred[:, :config.motion.epfl_target_length_train] + offset\n",
    "    else:\n",
    "        motion_pred = motion_pred[:, :config.motion.epfl_target_length_train]\n",
    "\n",
    "    #E Compute the loss between the predicted motion and the target motion.\n",
    "    #E Reshape predictions and targets to (b, n, 17, 3) format\n",
    "    b_target, n_target, _, _ = epfl_motion_target.shape\n",
    "    motion_pred = motion_pred.reshape(b_target, n_target, 17, 3)\n",
    "    \n",
    "    # Compute position loss\n",
    "    position_loss = torch.mean(torch.norm(motion_pred - epfl_motion_target.cuda(), 2, 3))\n",
    "\n",
    "    #E This computes the velocity loss and adds it to the position loss.\n",
    "    velocity_loss = 0.0\n",
    "    if config.use_relative_loss:\n",
    "        dmotion_pred = gen_velocity(motion_pred)\n",
    "        dmotion_gt = gen_velocity(epfl_motion_target.cuda())\n",
    "        velocity_loss = torch.mean(torch.norm(dmotion_pred - dmotion_gt, 2, 3))\n",
    "        loss = position_loss + velocity_loss\n",
    "    else:\n",
    "        loss = position_loss\n",
    "\n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"train/loss\": loss.detach().cpu().item(),\n",
    "        \"train/position_loss\": position_loss.detach().cpu().item(),\n",
    "        \"train/velocity_loss\": velocity_loss.detach().cpu().item() if config.use_relative_loss else 0.0,\n",
    "        \"train/iteration\": nb_iter\n",
    "    })\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer, current_lr = update_lr_multistep(nb_iter, total_iter, max_lr, min_lr, optimizer)\n",
    "    \n",
    "    # Log learning rate to wandb\n",
    "    wandb.log({\n",
    "        \"train/learning_rate\": current_lr,\n",
    "        \"train/iteration\": nb_iter\n",
    "    })\n",
    "\n",
    "    return loss.item(), optimizer, current_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f211b945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siMLPe(\n",
       "  (arr0): Rearrange('b n d -> b d n')\n",
       "  (arr1): Rearrange('b d n -> b n d')\n",
       "  (motion_mlp): TransMLP(\n",
       "    (mlps): Sequential(\n",
       "      (0): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (1): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (2): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (3): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (4): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (5): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (6): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (7): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (8): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (9): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (10): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (11): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (12): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (13): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (14): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (15): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (16): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (17): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (18): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (19): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (20): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (21): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (22): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (23): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (24): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (25): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (26): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (27): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (28): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (29): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (30): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (31): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (32): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (33): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (34): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (35): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (36): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (37): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (38): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (39): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (40): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (41): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (42): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (43): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (44): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (45): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (46): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "      (47): MLPblock(\n",
       "        (fc0): Temporal_FC(\n",
       "          (fc): Linear(in_features=50, out_features=50, bias=True)\n",
       "        )\n",
       "        (norm0): LN()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (motion_fc_in): Linear(in_features=51, out_features=51, bias=True)\n",
       "  (motion_fc_out): Linear(in_features=51, out_features=51, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(config)\n",
    "model.train()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe44ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EPFLSK30Dataset(config, 'train', config.data_aug)\n",
    "\n",
    "shuffle = True\n",
    "sampler = None\n",
    "dataloader = DataLoader(dataset, batch_size=config.batch_size,\n",
    "                        num_workers=config.num_workers, drop_last=True,\n",
    "                        sampler=sampler, shuffle=shuffle, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0360ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = copy.deepcopy(config)\n",
    "eval_dataset = EPFLSK30Eval(eval_config, 'test')\n",
    "\n",
    "\n",
    "shuffle = False\n",
    "sampler = None\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=128,\n",
    "                        num_workers=1, drop_last=False,\n",
    "                        sampler=sampler, shuffle=shuffle, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6588e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/40000 [00:00<?, ?iter/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 4999/40000 [03:48<26:16, 22.20iter/s, loss=0.0398, lr=3.00e-04, iter=4999]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "Training:  13%|█▎        | 5003/40000 [06:34<126:14:05, 12.99s/iter, loss=0.0367, lr=3.00e-04, iter=5003]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.2, 10.9, 23.7, 30.2, 44.1, 57.7, 70.9, 80.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 10004/40000 [13:08<114:00:54, 13.68s/iter, loss=0.0415, lr=3.00e-04, iter=1e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.7, 10.0, 22.1, 28.4, 41.1, 54.0, 66.8, 76.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 15004/40000 [19:41<87:32:16, 12.61s/iter, loss=0.0353, lr=3.00e-04, iter=15004] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5, 9.7, 21.8, 28.3, 41.1, 54.0, 66.9, 76.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 20003/40000 [26:18<78:58:08, 14.22s/iter, loss=0.0325, lr=3.00e-04, iter=2e+4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3, 9.2, 20.3, 26.0, 37.7, 50.0, 62.4, 71.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|██████▎   | 25004/40000 [32:53<52:27:53, 12.59s/iter, loss=0.0373, lr=3.00e-04, iter=25004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2, 9.0, 20.0, 25.6, 37.3, 49.7, 62.5, 71.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 30004/40000 [39:30<38:04:46, 13.71s/iter, loss=0.0351, lr=1.00e-05, iter=3e+4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.8, 8.4, 18.8, 24.1, 34.8, 46.2, 58.2, 67.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 35004/40000 [46:05<17:58:40, 12.95s/iter, loss=0.0342, lr=1.00e-05, iter=35004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6, 8.1, 18.2, 23.3, 33.4, 44.0, 55.3, 64.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40000/40000 [52:41<00:00, 12.65iter/s, loss=0.0319, lr=1.00e-05, iter=4e+4]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6, 8.0, 18.1, 23.2, 33.6, 44.5, 56.1, 64.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_0</td><td>█▆▅▄▄▂▁▁</td></tr><tr><td>eval/accuracy_1</td><td>█▆▅▄▃▂▁▁</td></tr><tr><td>eval/accuracy_2</td><td>█▆▆▄▃▂▁▁</td></tr><tr><td>eval/accuracy_3</td><td>█▆▆▄▃▂▁▁</td></tr><tr><td>eval/accuracy_4</td><td>█▆▆▄▄▂▁▁</td></tr><tr><td>eval/accuracy_5</td><td>█▆▆▄▄▂▁▁</td></tr><tr><td>eval/accuracy_6</td><td>█▆▆▄▄▂▁▁</td></tr><tr><td>eval/accuracy_7</td><td>█▆▆▄▄▂▁▁</td></tr><tr><td>eval/iteration</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train/avg_loss</td><td>█▆▆▆▆▄▄▅▄▄▄▄▃▃▃▄▃▃▃▂▃▂▂▂▂▂▂▂▂▃▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_0</td><td>3.6</td></tr><tr><td>eval/accuracy_1</td><td>8</td></tr><tr><td>eval/accuracy_2</td><td>18.1</td></tr><tr><td>eval/accuracy_3</td><td>23.2</td></tr><tr><td>eval/accuracy_4</td><td>33.6</td></tr><tr><td>eval/accuracy_5</td><td>44.5</td></tr><tr><td>eval/accuracy_6</td><td>56.1</td></tr><tr><td>eval/accuracy_7</td><td>64.9</td></tr><tr><td>eval/iteration</td><td>40000</td></tr><tr><td>train/avg_loss</td><td>0.03186</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">epfl_sk30_baseline_downsample2</strong> at: <a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30/runs/d4snm1so' target=\"_blank\">https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30/runs/d4snm1so</a><br> View project at: <a href='https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30' target=\"_blank\">https://wandb.ai/emredmrcx-itu-edu-tr/siMLPe-EPFL-SK30</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 8 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251007_123612-d4snm1so/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=config.cos_lr_max,\n",
    "                             weight_decay=config.weight_decay)\n",
    "\n",
    "ensure_dir(config.snapshot_dir)\n",
    "logger = get_logger(config.log_file, 'train')\n",
    "link_file(config.log_file, config.link_log_file)\n",
    "\n",
    "print_and_log_info(logger, json.dumps(config, indent=4, sort_keys=True))\n",
    "\n",
    "if config.model_pth is not None :\n",
    "    state_dict = torch.load(config.model_pth)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    print_and_log_info(logger, \"Loading model path from {} \".format(config.model_pth))\n",
    "    \n",
    "# Log model architecture to wandb\n",
    "wandb.watch(model, log=\"all\", log_freq=1000)\n",
    "\n",
    "##### ------ training ------- #####\n",
    "nb_iter = 0\n",
    "avg_loss = 0.\n",
    "avg_lr = 0.\n",
    "\n",
    "#E Training loop \n",
    "print(\"training loop\")\n",
    "pbar = tqdm(total=config.cos_lr_total_iters, desc=\"Training\", unit=\"iter\")\n",
    "\n",
    "while (nb_iter + 1) < config.cos_lr_total_iters:\n",
    "\n",
    "    for (epfl_motion_input, epfl_motion_target) in dataloader:\n",
    "\n",
    "        loss, optimizer, current_lr = train_step(epfl_motion_input, epfl_motion_target, model, optimizer, nb_iter, config.cos_lr_total_iters, config.cos_lr_max, config.cos_lr_min)\n",
    "        avg_loss += loss\n",
    "        avg_lr += current_lr\n",
    "\n",
    "        if (nb_iter + 1) % config.print_every ==  0 :\n",
    "            avg_loss = avg_loss / config.print_every\n",
    "            avg_lr = avg_lr / config.print_every\n",
    "\n",
    "            print_and_log_info(logger, \"Iter {} Summary: \".format(nb_iter + 1))\n",
    "            print_and_log_info(logger, f\"\\t lr: {avg_lr} \\t Training loss: {avg_loss}\")\n",
    "            \n",
    "            # Log averaged metrics to wandb\n",
    "            wandb.log({\n",
    "                \"train/avg_loss\": avg_loss,\n",
    "                \"train/avg_lr\": avg_lr,\n",
    "                \"train/iteration\": nb_iter + 1\n",
    "            })\n",
    "            \n",
    "            avg_loss = 0\n",
    "            avg_lr = 0\n",
    "\n",
    "        if (nb_iter + 1) % config.save_every ==  0 :\n",
    "        \n",
    "            # Save model checkpoint\n",
    "            model_path = config.snapshot_dir + '/model-iter-' + str(nb_iter + 1) + '.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # Save model artifact to wandb\n",
    "            wandb.save(model_path)\n",
    "            \n",
    "            # Evaluate model\n",
    "            model.eval()\n",
    "            acc_tmp = test(eval_config, model, eval_dataloader)\n",
    "            print(acc_tmp)\n",
    "            \n",
    "            # Log evaluation metrics to wandb\n",
    "            eval_metrics = {\"eval/iteration\": nb_iter + 1}\n",
    "            \n",
    "            # Log all accuracy values from acc_tmp\n",
    "            for i, acc_value in enumerate(acc_tmp):\n",
    "                eval_metrics[f\"eval/accuracy_{i}\"] = acc_value\n",
    "            \n",
    "            wandb.log(eval_metrics)\n",
    "            \n",
    "            acc_log.write(''.join(str(nb_iter + 1) + '\\n'))\n",
    "            line = ''\n",
    "            for ii in acc_tmp:\n",
    "                line += str(ii) + ' '\n",
    "            line += '\\n'\n",
    "            acc_log.write(''.join(line))\n",
    "            model.train()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss:.4f}',\n",
    "            'lr': f'{current_lr:.2e}',\n",
    "            'iter': nb_iter + 1\n",
    "        })\n",
    "\n",
    "        if (nb_iter + 1) == config.cos_lr_total_iters :\n",
    "            break\n",
    "        nb_iter += 1\n",
    "\n",
    "pbar.close()\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b53d1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simlpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
